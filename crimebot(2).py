# -*- coding: utf-8 -*-
"""crimebot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yY1RALB26g9PayHknrgtQKjJDo1w_8_S
"""

!pip install openai==0.28

!openai migrate

import numpy as np
import pandas as pd
import openai
import nltk
import string
import random
import time
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

openai.api_key = 'sk-None-y311uYNkT17vlwOGjkyRT3BlbkFJfIXR5O9pHzMKlhDj6f2i'

"""Load the statistical data"""

try:
    ipc_crimes_df = pd.read_csv('/content/IPC CRIMES 2019.csv')
    crime_foreigners_2022_df = pd.read_csv('/content/crimeheldwithforeigners2022.csv')
    crime_foreigners_2017_2021_df = pd.read_csv('/content/crimesheldwithforeigners2017-2021.csv')
except FileNotFoundError as e:
    print(f"Error: {e}")
    exit()

nltk.download('punkt')
nltk.download('wordnet')

""" Combine text from all the data files into a single raw string for tokenization"""

raw = ipc_crimes_df.to_string() + crime_foreigners_2022_df.to_string() + crime_foreigners_2017_2021_df.to_string()
raw = raw.lower()
sent_tokens = nltk.sent_tokenize(raw)
word_tokens = nltk.word_tokenize(raw)

lemmer = nltk.stem.WordNetLemmatizer()
def LemTokens(tokens):
    return [lemmer.lemmatize(token) for token in tokens]
remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)
def LemNormalize(text):
    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

GREET_INPUT = ("hello", "hi", "greetings", "sup", "what's up","hey")
GREET_RESPONSE = ["hi", "hey", "*nods*", "hi there", "hello", "I am glad! You are talking to me"]
def greet(sentence):
    for word in sentence.split():
        if word.lower() in GREET_INPUT:
            return random.choice(GREET_RESPONSE)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""Create and train a logistic regression model"""

def train_model():
    # Dummy labels for example purposes
    data = {
        'text': sent_tokens,
        'label': [random.choice([0, 1]) for _ in range(len(sent_tokens))]
    }
    df = pd.DataFrame(data)

    # Convert text to TF-IDF features
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')
    X = TfidfVec.fit_transform(df['text'])
    y = df['label']

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train the model
    model = LogisticRegression()
    model.fit(X_train, y_train)

    # Test the model
    y_pred = model.predict(X_test)
    print(f"Accuracy: {accuracy_score(y_test, y_pred)}")

    return model, TfidfVec

model, TfidfVec = train_model()

def response(user_response):
    robo1_response = ''
    tfidf = TfidfVec.transform([user_response])
    prediction = model.predict(tfidf)[0]
    if prediction == 0:
        robo1_response = "I am sorry! I don't understand you"
    else:
        vals = cosine_similarity(tfidf, TfidfVec.transform(sent_tokens))
        idx = vals.argsort()[0][-2]
        robo1_response = sent_tokens[idx]
    return robo1_response

def chatgpt_response(prompt, max_retries=3, retry_delay=5):
    retries = 0
    while retries < max_retries:
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                n=1,
                stop=None,
                temperature=0.7,
            )
            return response.choices[0].message.content.strip()
        except openai.error.RateLimitError:
            retries += 1
            print(f"Rate limit exceeded. Retrying in {retry_delay} seconds... (Attempt {retries})")
            time.sleep(retry_delay)
        except Exception as e:
            print(f"An error occurred: {e}")
            break
    print("Max retries reached or error occurred. Unable to get a response.")
    return None

def fetch_statistics(query):
    response = ""

    # Check in IPC CRIMES 2019
    if 'ipc crimes 2019' in query.lower():
        for index, row in ipc_crimes_df.iterrows():
            if query.lower() in row.to_string().lower():
                response += f"{row.to_string()}\n"

    # Check in crimeheldwithforeigners2022
    if 'crime foreigners 2022' in query.lower():
        for index, row in crime_foreigners_2022_df.iterrows():
            if query.lower() in row.to_string().lower():
                response += f"{row.to_string()}\n"

    # Check in crimesheldwithforeigners2017-2021
    if 'crime foreigners 2017 2021' in query.lower():
        for index, row in crime_foreigners_2017_2021_df.iterrows():
            if query.lower() in row.to_string().lower():
                response += f"{row.to_string()}\n"

    return response if response else "I couldn't find any statistics related to your query."

flag = True
print("ROBO: My name is Robo. Let's have a conversation! Also, if you want to exit any time, just type Bye!")

while flag:
    user_response = input()
    user_response = user_response.lower()
    if user_response != 'bye':
        if user_response == 'thanks' or user_response == 'thank you':
            flag = False
            print("ROBO: You are welcome..")
        else:
            if greet(user_response) is not None:
                print("ROBO: " + greet(user_response))
            else:
                sent_tokens.append(user_response)
                word_tokens = word_tokens + nltk.word_tokenize(user_response)
                final_words = list(set(word_tokens))
                print("ROBO: ", end="")
                bot_response = response(user_response)
                if "I am sorry! I don't understand you" in bot_response:
                    # Try to fetch statistics first
                    stats_response = fetch_statistics(user_response)
                    if stats_response == "I couldn't find any statistics related to your query.":
                        # If no statistics found, use ChatGPT response
                        bot_response = chatgpt_response(user_response)
                    else:
                        bot_response = stats_response
                print(bot_response)
                sent_tokens.remove(user_response)
    else:
        flag = False
        print("ROBO: Bye! take care..")